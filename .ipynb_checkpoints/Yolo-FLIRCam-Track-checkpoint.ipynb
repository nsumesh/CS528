{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c837d46-0d8f-4e0c-a59d-7fd024539d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PySpin\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ce47d-99b1-4889-8f16-3f4ad2173fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64bdfc22-1e6a-4676-aff2-429188480094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_camera(camera):\n",
    "    # Changes amount of frame captured in camera\n",
    "    width = int(2448 / 1)\n",
    "    height = int(2048 / 1)\n",
    "\n",
    "    # Reset Camera\n",
    "    nodemap = camera.GetNodeMap()\n",
    "    user_set_selector = PySpin.CEnumerationPtr(nodemap.GetNode(\"UserSetSelector\"))\n",
    "    default_set = user_set_selector.GetEntryByName(\"Default\")\n",
    "    user_set_selector.SetIntValue(default_set.GetValue())\n",
    "    user_set_load = PySpin.CCommandPtr(nodemap.GetNode(\"UserSetLoad\"))\n",
    "    user_set_load.Execute()\n",
    "    \n",
    "    if camera.PixelFormat.GetAccessMode() == PySpin.RW:\n",
    "        camera.PixelFormat.SetValue(PySpin.PixelFormat_RGB8)\n",
    "        print(\"Pixel format set to color.\")\n",
    "    else:\n",
    "        print(\"Color pixel format not supported.\")\n",
    "\n",
    "    # Retrieve the nodemap\n",
    "    nodemap = camera.GetNodeMap()\n",
    "\n",
    "    # Get width and height nodes\n",
    "    node_width = PySpin.CIntegerPtr(nodemap.GetNode(\"Width\"))\n",
    "    node_height = PySpin.CIntegerPtr(nodemap.GetNode(\"Height\"))\n",
    "    node_width_max = node_width.GetMax()\n",
    "    node_height_max = node_height.GetMax()\n",
    "\n",
    "    # Calculate offsets to center the image\n",
    "    offset_x = (node_width_max - width) // 2\n",
    "    offset_y = (node_height_max - height) // 2\n",
    "\n",
    "    # Set width and height\n",
    "    node_offset_x = PySpin.CIntegerPtr(nodemap.GetNode(\"OffsetX\"))\n",
    "    node_offset_y = PySpin.CIntegerPtr(nodemap.GetNode(\"OffsetY\"))\n",
    "\n",
    "    node_width.SetValue(width)\n",
    "    node_height.SetValue(height)\n",
    "    node_offset_x.SetValue(offset_x)\n",
    "    node_offset_y.SetValue(offset_y)\n",
    "\n",
    "    camera.AcquisitionMode.SetValue(PySpin.AcquisitionMode_SingleFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64df2f48-2cb4-41d7-8430-81a872b8feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_and_process_image(camera, model, video_writer, csv_writer):\n",
    "    camera.BeginAcquisition()\n",
    "    image_result = camera.GetNextImage()\n",
    "    if image_result.IsIncomplete():\n",
    "        print('Image incomplete with image status %d ...' % image_result.GetImageStatus())\n",
    "        image_result.Release()\n",
    "        camera.EndAcquisition()\n",
    "        return True\n",
    "\n",
    "    image_data = image_result.GetNDArray()\n",
    "    image_result.Release()\n",
    "    camera.EndAcquisition()\n",
    "    \n",
    "    # Convert to a format that can be displayed with OpenCV\n",
    "    image_data = cv2.resize(image_data, (640, 640))\n",
    "    image_data = cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Perform detection\n",
    "    results = model.predict(image_data, classes=0, agnostic_nms=False, verbose=False)[0]\n",
    "    annotator = Annotator(image_data)\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            annotator.box_label(box.xyxy[0], model.names[int(box.cls)])\n",
    "            csv_writer.writerow([timestamp, *box.xyxy[0], box.conf[0], model.names[int(box.cls)]])\n",
    "\n",
    "    # Save the frame to video\n",
    "    video_writer.write(cv2.cvtColor(image_data, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Display the annotated image\n",
    "    annotated_image = annotator.result()\n",
    "    cv2.imshow('Processed Image', annotated_image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4574dc2-b387-4b11-a9ac-ce3fe3f79fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    system = PySpin.System.GetInstance()\n",
    "    cam_list = system.GetCameras()\n",
    "    if cam_list.GetSize() == 0:\n",
    "        print('No cameras found.')\n",
    "        return\n",
    "\n",
    "    camera = cam_list.GetByIndex(0)\n",
    "    camera.Init()\n",
    "    configure_camera(camera)\n",
    "\n",
    "    model = YOLO(\"yolov8n.pt\")  # Load your YOLO model\n",
    "\n",
    "    # Setup video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter('output_video.mp4', fourcc, 20.0, (640, 640))\n",
    "\n",
    "    # Setup CSV writer\n",
    "    csv_file = open('detections.csv', 'w', newline='')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['Timestamp', 'X1', 'Y1', 'X2', 'Y2', 'Confidence', 'Class'])\n",
    "\n",
    "    while True:\n",
    "        if not capture_and_process_image(camera, model, video_writer, csv_writer):\n",
    "            break\n",
    "\n",
    "    camera.DeInit()\n",
    "    del camera\n",
    "    cam_list.Clear()\n",
    "    system.ReleaseInstance()\n",
    "    cv2.destroyAllWindows()\n",
    "    video_writer.release()\n",
    "    csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f061c8c-6715-45e1-85db-564ca54a002e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel format set to color.\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.3923])\n",
      "data: tensor([[1.1507e+00, 3.9213e+00, 5.4762e+02, 6.2701e+02, 3.9227e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[274.3851, 315.4661, 546.4689, 623.0896]])\n",
      "xywhn: tensor([[0.4287, 0.4929, 0.8539, 0.9736]])\n",
      "xyxy: tensor([[  1.1507,   3.9213, 547.6196, 627.0109]])\n",
      "xyxyn: tensor([[0.0018, 0.0061, 0.8557, 0.9797]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.3570])\n",
      "data: tensor([[1.0160e+01, 1.1706e+01, 4.9250e+02, 6.1577e+02, 3.5697e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[251.3295, 313.7383, 482.3392, 604.0646]])\n",
      "xywhn: tensor([[0.3927, 0.4902, 0.7537, 0.9439]])\n",
      "xyxy: tensor([[ 10.1599,  11.7060, 492.4991, 615.7706]])\n",
      "xyxyn: tensor([[0.0159, 0.0183, 0.7695, 0.9621]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.2806])\n",
      "data: tensor([[0.0000e+00, 1.2775e+01, 4.9282e+02, 6.1412e+02, 2.8055e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[246.4077, 313.4486, 492.8153, 601.3469]])\n",
      "xywhn: tensor([[0.3850, 0.4898, 0.7700, 0.9396]])\n",
      "xyxy: tensor([[  0.0000,  12.7751, 492.8153, 614.1221]])\n",
      "xyxyn: tensor([[0.0000, 0.0200, 0.7700, 0.9596]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.3068])\n",
      "data: tensor([[8.6493e-01, 1.2073e+01, 4.9272e+02, 6.1362e+02, 3.0681e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[246.7947, 312.8473, 491.8596, 601.5479]])\n",
      "xywhn: tensor([[0.3856, 0.4888, 0.7685, 0.9399]])\n",
      "xyxy: tensor([[  0.8649,  12.0734, 492.7245, 613.6212]])\n",
      "xyxyn: tensor([[0.0014, 0.0189, 0.7699, 0.9588]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.3078])\n",
      "data: tensor([[1.3389e+02, 1.1337e+01, 4.9253e+02, 6.0962e+02, 3.0780e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[313.2078, 310.4803, 358.6454, 598.2869]])\n",
      "xywhn: tensor([[0.4894, 0.4851, 0.5604, 0.9348]])\n",
      "xyxy: tensor([[133.8851,  11.3369, 492.5305, 609.6238]])\n",
      "xyxyn: tensor([[0.2092, 0.0177, 0.7696, 0.9525]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.2551])\n",
      "data: tensor([[1.7648e+02, 6.2354e+00, 4.9167e+02, 5.7636e+02, 2.5506e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[334.0723, 291.2962, 315.1913, 570.1218]])\n",
      "xywhn: tensor([[0.5220, 0.4552, 0.4925, 0.8908]])\n",
      "xyxy: tensor([[176.4766,   6.2354, 491.6679, 576.3571]])\n",
      "xyxyn: tensor([[0.2757, 0.0097, 0.7682, 0.9006]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.3116])\n",
      "data: tensor([[1.8885e+02, 1.7118e+01, 4.9634e+02, 6.2495e+02, 3.1156e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[342.5986, 321.0327, 307.4921, 607.8287]])\n",
      "xywhn: tensor([[0.5353, 0.5016, 0.4805, 0.9497]])\n",
      "xyxy: tensor([[188.8526,  17.1183, 496.3447, 624.9470]])\n",
      "xyxyn: tensor([[0.2951, 0.0267, 0.7755, 0.9765]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.3111])\n",
      "data: tensor([[1.1861e+00, 5.6270e+00, 3.9598e+02, 6.3682e+02, 3.1106e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[198.5809, 321.2250, 394.7896, 631.1960]])\n",
      "xywhn: tensor([[0.3103, 0.5019, 0.6169, 0.9862]])\n",
      "xyxy: tensor([[  1.1861,   5.6270, 395.9757, 636.8230]])\n",
      "xyxyn: tensor([[0.0019, 0.0088, 0.6187, 0.9950]])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74eb76-1663-4191-9877-fce88c077943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
