{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c837d46-0d8f-4e0c-a59d-7fd024539d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PySpin\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ce47d-99b1-4889-8f16-3f4ad2173fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64bdfc22-1e6a-4676-aff2-429188480094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_camera(camera):\n",
    "    # Changes amount of frame captured in camera\n",
    "    width = int(2448 / 1)\n",
    "    height = int(2048 / 1)\n",
    "\n",
    "    # Reset Camera\n",
    "    nodemap = camera.GetNodeMap()\n",
    "    user_set_selector = PySpin.CEnumerationPtr(nodemap.GetNode(\"UserSetSelector\"))\n",
    "    default_set = user_set_selector.GetEntryByName(\"Default\")\n",
    "    user_set_selector.SetIntValue(default_set.GetValue())\n",
    "    user_set_load = PySpin.CCommandPtr(nodemap.GetNode(\"UserSetLoad\"))\n",
    "    user_set_load.Execute()\n",
    "    \n",
    "    if camera.PixelFormat.GetAccessMode() == PySpin.RW:\n",
    "        camera.PixelFormat.SetValue(PySpin.PixelFormat_RGB8)\n",
    "        print(\"Pixel format set to color.\")\n",
    "    else:\n",
    "        print(\"Color pixel format not supported.\")\n",
    "\n",
    "    # Retrieve the nodemap\n",
    "    nodemap = camera.GetNodeMap()\n",
    "\n",
    "    # Get width and height nodes\n",
    "    node_width = PySpin.CIntegerPtr(nodemap.GetNode(\"Width\"))\n",
    "    node_height = PySpin.CIntegerPtr(nodemap.GetNode(\"Height\"))\n",
    "    node_width_max = node_width.GetMax()\n",
    "    node_height_max = node_height.GetMax()\n",
    "\n",
    "    # Calculate offsets to center the image\n",
    "    offset_x = (node_width_max - width) // 2\n",
    "    offset_y = (node_height_max - height) // 2\n",
    "\n",
    "    # Set width and height\n",
    "    node_offset_x = PySpin.CIntegerPtr(nodemap.GetNode(\"OffsetX\"))\n",
    "    node_offset_y = PySpin.CIntegerPtr(nodemap.GetNode(\"OffsetY\"))\n",
    "\n",
    "    node_width.SetValue(width)\n",
    "    node_height.SetValue(height)\n",
    "    node_offset_x.SetValue(offset_x)\n",
    "    node_offset_y.SetValue(offset_y)\n",
    "\n",
    "    camera.AcquisitionMode.SetValue(PySpin.AcquisitionMode_SingleFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64df2f48-2cb4-41d7-8430-81a872b8feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_and_process_image(camera, model, video_writer, csv_writer):\n",
    "    camera.BeginAcquisition()\n",
    "    image_result = camera.GetNextImage()\n",
    "    if image_result.IsIncomplete():\n",
    "        print('Image incomplete with image status %d ...' % image_result.GetImageStatus())\n",
    "        image_result.Release()\n",
    "        camera.EndAcquisition()\n",
    "        return True\n",
    "\n",
    "    image_data = image_result.GetNDArray()\n",
    "    image_result.Release()\n",
    "    camera.EndAcquisition()\n",
    "    \n",
    "    # Convert to a format that can be displayed with OpenCV\n",
    "    image_data = cv2.resize(image_data, (640, 640))\n",
    "    image_data = cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Perform detection\n",
    "    results = model.track(image_data, classes=0, agnostic_nms=False, verbose=False, persist = True)[0]\n",
    "    annotator = Annotator(image_data)\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            print(box)\n",
    "            annotator.box_label(box.xyxy[0], model.names[int(box.cls)])\n",
    "            csv_writer.writerow([timestamp, *box.xyxy[0], box.conf[0], model.names[int(box.cls)]])\n",
    "\n",
    "    # Save the frame to video\n",
    "    video_writer.write(cv2.cvtColor(image_data, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Display the annotated image\n",
    "    annotated_image = annotator.result()\n",
    "    cv2.imshow('Processed Image', annotated_image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4574dc2-b387-4b11-a9ac-ce3fe3f79fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    system = PySpin.System.GetInstance()\n",
    "    cam_list = system.GetCameras()\n",
    "    if cam_list.GetSize() == 0:\n",
    "        print('No cameras found.')\n",
    "        return\n",
    "\n",
    "    camera = cam_list.GetByIndex(0)\n",
    "    camera.Init()\n",
    "    configure_camera(camera)\n",
    "\n",
    "    model = YOLO(\"yolov8n.pt\")  # Load your YOLO model\n",
    "\n",
    "    # Setup video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter('output_video.mp4', fourcc, 20.0, (640, 640))\n",
    "\n",
    "    # Setup CSV writer\n",
    "    csv_file = open('detections.csv', 'w', newline='')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['Timestamp', 'X1', 'Y1', 'X2', 'Y2', 'Confidence', 'Class'])\n",
    "\n",
    "    while True:\n",
    "        if not capture_and_process_image(camera, model, video_writer, csv_writer):\n",
    "            break\n",
    "\n",
    "    camera.DeInit()\n",
    "    del camera\n",
    "    cam_list.Clear()\n",
    "    system.ReleaseInstance()\n",
    "    cv2.destroyAllWindows()\n",
    "    video_writer.release()\n",
    "    csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f061c8c-6715-45e1-85db-564ca54a002e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel format set to color.\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.5595])\n",
      "data: tensor([[3.4380e+01, 1.0800e+01, 4.8936e+02, 6.3089e+02, 5.5948e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[261.8710, 320.8430, 454.9829, 620.0861]])\n",
      "xywhn: tensor([[0.4092, 0.5013, 0.7109, 0.9689]])\n",
      "xyxy: tensor([[ 34.3795,  10.8000, 489.3624, 630.8860]])\n",
      "xyxyn: tensor([[0.0537, 0.0169, 0.7646, 0.9858]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.4941])\n",
      "data: tensor([[3.6412e+00, 3.1714e+00, 6.1655e+02, 6.3796e+02, 4.9414e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[310.0939, 320.5652, 612.9054, 634.7875]])\n",
      "xywhn: tensor([[0.4845, 0.5009, 0.9577, 0.9919]])\n",
      "xyxy: tensor([[  3.6412,   3.1714, 616.5466, 637.9589]])\n",
      "xyxyn: tensor([[0.0057, 0.0050, 0.9634, 0.9968]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.2635])\n",
      "data: tensor([[1.8234e+02, 1.4104e+01, 4.9043e+02, 5.7992e+02, 2.6355e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[336.3853, 297.0133, 308.0922, 565.8184]])\n",
      "xywhn: tensor([[0.5256, 0.4641, 0.4814, 0.8841]])\n",
      "xyxy: tensor([[182.3391,  14.1041, 490.4314, 579.9225]])\n",
      "xyxyn: tensor([[0.2849, 0.0220, 0.7663, 0.9061]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.1208])\n",
      "data: tensor([[1.7533e+02, 3.4872e+00, 5.6882e+02, 6.3675e+02, 1.2075e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[372.0771, 320.1205, 393.4844, 633.2664]])\n",
      "xywhn: tensor([[0.5814, 0.5002, 0.6148, 0.9895]])\n",
      "xyxy: tensor([[175.3348,   3.4872, 568.8193, 636.7537]])\n",
      "xyxyn: tensor([[0.2740, 0.0054, 0.8888, 0.9949]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.3013])\n",
      "data: tensor([[1.8624e+02, 1.9840e+01, 4.8896e+02, 6.3780e+02, 3.0127e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[337.6028, 328.8190, 302.7198, 617.9576]])\n",
      "xywhn: tensor([[0.5275, 0.5138, 0.4730, 0.9656]])\n",
      "xyxy: tensor([[186.2429,  19.8402, 488.9628, 637.7979]])\n",
      "xyxyn: tensor([[0.2910, 0.0310, 0.7640, 0.9966]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.2328])\n",
      "data: tensor([[2.1854e+00, 1.5670e+01, 5.5656e+02, 6.3603e+02, 2.3280e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[279.3741, 325.8508, 554.3774, 620.3622]])\n",
      "xywhn: tensor([[0.4365, 0.5091, 0.8662, 0.9693]])\n",
      "xyxy: tensor([[  2.1854,  15.6697, 556.5629, 636.0319]])\n",
      "xyxyn: tensor([[0.0034, 0.0245, 0.8696, 0.9938]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.1168])\n",
      "data: tensor([[1.8722e+02, 3.8151e+01, 4.8150e+02, 4.8311e+02, 1.1676e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[334.3588, 260.6322, 294.2757, 444.9628]])\n",
      "xywhn: tensor([[0.5224, 0.4072, 0.4598, 0.6953]])\n",
      "xyxy: tensor([[187.2209,  38.1508, 481.4966, 483.1136]])\n",
      "xyxyn: tensor([[0.2925, 0.0596, 0.7523, 0.7549]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.4321])\n",
      "data: tensor([[1.7667e+02, 1.8838e+01, 4.9231e+02, 6.3739e+02, 4.3207e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[334.4929, 328.1136, 315.6411, 618.5513]])\n",
      "xywhn: tensor([[0.5226, 0.5127, 0.4932, 0.9665]])\n",
      "xyxy: tensor([[176.6723,  18.8380, 492.3134, 637.3893]])\n",
      "xyxyn: tensor([[0.2761, 0.0294, 0.7692, 0.9959]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.3708])\n",
      "data: tensor([[1.5674e+00, 1.3315e+01, 4.9851e+02, 6.3682e+02, 3.7076e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[250.0370, 325.0674, 496.9392, 623.5052]])\n",
      "xywhn: tensor([[0.3907, 0.5079, 0.7765, 0.9742]])\n",
      "xyxy: tensor([[  1.5674,  13.3148, 498.5066, 636.8201]])\n",
      "xyxyn: tensor([[0.0024, 0.0208, 0.7789, 0.9950]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.4850])\n",
      "data: tensor([[1.8910e+02, 2.7310e+01, 4.9089e+02, 6.0681e+02, 4.8500e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[339.9936, 317.0582, 301.7911, 579.4968]])\n",
      "xywhn: tensor([[0.5312, 0.4954, 0.4715, 0.9055]])\n",
      "xyxy: tensor([[189.0981,  27.3098, 490.8892, 606.8066]])\n",
      "xyxyn: tensor([[0.2955, 0.0427, 0.7670, 0.9481]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.1223])\n",
      "data: tensor([[1.5486e+00, 1.4143e+01, 5.7676e+02, 6.3673e+02, 1.2233e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[289.1545, 325.4346, 575.2118, 622.5828]])\n",
      "xywhn: tensor([[0.4518, 0.5085, 0.8988, 0.9728]])\n",
      "xyxy: tensor([[  1.5486,  14.1432, 576.7604, 636.7260]])\n",
      "xyxyn: tensor([[0.0024, 0.0221, 0.9012, 0.9949]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.2648])\n",
      "data: tensor([[1.8629e+02, 2.7562e+01, 4.8808e+02, 6.1019e+02, 2.6483e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[337.1863, 318.8750, 301.7886, 582.6252]])\n",
      "xywhn: tensor([[0.5269, 0.4982, 0.4715, 0.9104]])\n",
      "xyxy: tensor([[186.2921,  27.5624, 488.0806, 610.1876]])\n",
      "xyxyn: tensor([[0.2911, 0.0431, 0.7626, 0.9534]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.2474])\n",
      "data: tensor([[1.5627e+00, 8.7851e+00, 5.9182e+02, 6.3677e+02, 2.4744e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[296.6924, 322.7783, 590.2593, 627.9864]])\n",
      "xywhn: tensor([[0.4636, 0.5043, 0.9223, 0.9812]])\n",
      "xyxy: tensor([[  1.5627,   8.7851, 591.8220, 636.7715]])\n",
      "xyxyn: tensor([[0.0024, 0.0137, 0.9247, 0.9950]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.3026])\n",
      "data: tensor([[1.9358e+02, 2.0462e+01, 4.9513e+02, 6.3514e+02, 3.0261e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[344.3579, 327.7994, 301.5481, 614.6740]])\n",
      "xywhn: tensor([[0.5381, 0.5122, 0.4712, 0.9604]])\n",
      "xyxy: tensor([[193.5839,  20.4624, 495.1320, 635.1364]])\n",
      "xyxyn: tensor([[0.3025, 0.0320, 0.7736, 0.9924]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.2625])\n",
      "data: tensor([[1.8107e+00, 1.1137e+01, 5.9420e+02, 6.3651e+02, 2.6245e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[298.0075, 323.8232, 592.3935, 625.3715]])\n",
      "xywhn: tensor([[0.4656, 0.5060, 0.9256, 0.9771]])\n",
      "xyxy: tensor([[  1.8107,  11.1375, 594.2042, 636.5089]])\n",
      "xyxyn: tensor([[0.0028, 0.0174, 0.9284, 0.9945]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.1427])\n",
      "data: tensor([[1.9961e+02, 3.6115e+01, 4.8437e+02, 3.9628e+02, 1.4274e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[341.9918, 216.1978, 284.7543, 360.1650]])\n",
      "xywhn: tensor([[0.5344, 0.3378, 0.4449, 0.5628]])\n",
      "xyxy: tensor([[199.6146,  36.1153, 484.3690, 396.2803]])\n",
      "xyxyn: tensor([[0.3119, 0.0564, 0.7568, 0.6192]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.3290])\n",
      "data: tensor([[1.7365e+02, 2.1963e+01, 4.8939e+02, 6.3085e+02, 3.2898e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[331.5180, 326.4052, 315.7404, 608.8846]])\n",
      "xywhn: tensor([[0.5180, 0.5100, 0.4933, 0.9514]])\n",
      "xyxy: tensor([[173.6478,  21.9629, 489.3882, 630.8475]])\n",
      "xyxyn: tensor([[0.2713, 0.0343, 0.7647, 0.9857]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.2691])\n",
      "data: tensor([[1.7411e+00, 6.3108e+00, 6.1166e+02, 6.3666e+02, 2.6911e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[306.6995, 321.4829, 609.9169, 630.3442]])\n",
      "xywhn: tensor([[0.4792, 0.5023, 0.9530, 0.9849]])\n",
      "xyxy: tensor([[  1.7411,   6.3108, 611.6580, 636.6550]])\n",
      "xyxyn: tensor([[0.0027, 0.0099, 0.9557, 0.9948]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.1336])\n",
      "data: tensor([[1.9724e+02, 3.5458e+01, 4.8806e+02, 4.8840e+02, 1.3356e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[342.6516, 261.9307, 290.8154, 452.9456]])\n",
      "xywhn: tensor([[0.5354, 0.4093, 0.4544, 0.7077]])\n",
      "xyxy: tensor([[197.2439,  35.4580, 488.0593, 488.4035]])\n",
      "xyxyn: tensor([[0.3082, 0.0554, 0.7626, 0.7631]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.2288])\n",
      "data: tensor([[1.6812e+00, 1.0338e+01, 6.1834e+02, 6.3678e+02, 2.2879e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[310.0102, 323.5584, 616.6581, 626.4411]])\n",
      "xywhn: tensor([[0.4844, 0.5056, 0.9635, 0.9788]])\n",
      "xyxy: tensor([[  1.6812,  10.3378, 618.3392, 636.7789]])\n",
      "xyxyn: tensor([[0.0026, 0.0162, 0.9662, 0.9950]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.2173])\n",
      "data: tensor([[1.8903e+02, 2.6654e+01, 4.8842e+02, 6.1632e+02, 2.1731e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[338.7282, 321.4890, 299.3909, 589.6694]])\n",
      "xywhn: tensor([[0.5293, 0.5023, 0.4678, 0.9214]])\n",
      "xyxy: tensor([[189.0327,  26.6543, 488.4236, 616.3237]])\n",
      "xyxyn: tensor([[0.2954, 0.0416, 0.7632, 0.9630]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.1344])\n",
      "data: tensor([[1.9362e+02, 1.5041e+01, 3.9851e+02, 6.3199e+02, 1.3436e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[296.0663, 323.5141, 204.8931, 616.9454]])\n",
      "xywhn: tensor([[0.4626, 0.5055, 0.3201, 0.9640]])\n",
      "xyxy: tensor([[193.6198,  15.0414, 398.5128, 631.9868]])\n",
      "xyxyn: tensor([[0.3025, 0.0235, 0.6227, 0.9875]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.1034])\n",
      "data: tensor([[1.8775e+02, 4.7843e+00, 5.9616e+02, 6.3727e+02, 1.0341e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[391.9551, 321.0256, 408.4176, 632.4827]])\n",
      "xywhn: tensor([[0.6124, 0.5016, 0.6382, 0.9883]])\n",
      "xyxy: tensor([[187.7464,   4.7843, 596.1639, 637.2670]])\n",
      "xyxyn: tensor([[0.2934, 0.0075, 0.9315, 0.9957]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.2578])\n",
      "data: tensor([[1.7220e+02, 7.1688e+00, 4.8824e+02, 6.3294e+02, 2.5784e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[330.2188, 320.0534, 316.0461, 625.7693]])\n",
      "xywhn: tensor([[0.5160, 0.5001, 0.4938, 0.9778]])\n",
      "xyxy: tensor([[172.1958,   7.1688, 488.2419, 632.9381]])\n",
      "xyxyn: tensor([[0.2691, 0.0112, 0.7629, 0.9890]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.2308])\n",
      "data: tensor([[1.7460e+00, 7.2540e+00, 6.2355e+02, 6.3619e+02, 2.3077e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[312.6498, 321.7233, 621.8077, 628.9387]])\n",
      "xywhn: tensor([[0.4885, 0.5027, 0.9716, 0.9827]])\n",
      "xyxy: tensor([[  1.7460,   7.2540, 623.5537, 636.1927]])\n",
      "xyxyn: tensor([[0.0027, 0.0113, 0.9743, 0.9941]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.1412])\n",
      "data: tensor([[1.9710e+02, 3.7339e+01, 4.8876e+02, 4.7675e+02, 1.4118e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[342.9285, 257.0449, 291.6643, 439.4111]])\n",
      "xywhn: tensor([[0.5358, 0.4016, 0.4557, 0.6866]])\n",
      "xyxy: tensor([[197.0964,  37.3393, 488.7607, 476.7504]])\n",
      "xyxyn: tensor([[0.3080, 0.0583, 0.7637, 0.7449]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.3933])\n",
      "data: tensor([[1.9443e+02, 1.0774e+01, 4.8728e+02, 6.3460e+02, 3.9334e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[340.8565, 322.6876, 292.8431, 623.8280]])\n",
      "xywhn: tensor([[0.5326, 0.5042, 0.4576, 0.9747]])\n",
      "xyxy: tensor([[194.4349,  10.7736, 487.2781, 634.6016]])\n",
      "xyxyn: tensor([[0.3038, 0.0168, 0.7614, 0.9916]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.2424])\n",
      "data: tensor([[1.8047e+00, 7.9170e+00, 6.1829e+02, 6.3670e+02, 2.4241e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[310.0466, 322.3069, 616.4839, 628.7798]])\n",
      "xywhn: tensor([[0.4844, 0.5036, 0.9633, 0.9825]])\n",
      "xyxy: tensor([[  1.8047,   7.9170, 618.2886, 636.6968]])\n",
      "xyxyn: tensor([[0.0028, 0.0124, 0.9661, 0.9948]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.2883])\n",
      "data: tensor([[1.9271e+02, 5.7878e+00, 4.9336e+02, 6.3498e+02, 2.8831e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[343.0343, 320.3815, 300.6462, 629.1874]])\n",
      "xywhn: tensor([[0.5360, 0.5006, 0.4698, 0.9831]])\n",
      "xyxy: tensor([[192.7112,   5.7878, 493.3574, 634.9752]])\n",
      "xyxyn: tensor([[0.3011, 0.0090, 0.7709, 0.9921]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.2436])\n",
      "data: tensor([[1.9056e+00, 4.4321e+00, 6.2075e+02, 6.3632e+02, 2.4361e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[311.3295, 320.3771, 618.8477, 631.8900]])\n",
      "xywhn: tensor([[0.4865, 0.5006, 0.9669, 0.9873]])\n",
      "xyxy: tensor([[  1.9056,   4.4321, 620.7533, 636.3221]])\n",
      "xyxyn: tensor([[0.0030, 0.0069, 0.9699, 0.9943]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.4867])\n",
      "data: tensor([[1.7763e+02, 1.5536e+01, 4.8948e+02, 6.3636e+02, 4.8668e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[333.5547, 325.9489, 311.8530, 620.8257]])\n",
      "xywhn: tensor([[0.5212, 0.5093, 0.4873, 0.9700]])\n",
      "xyxy: tensor([[177.6283,  15.5361, 489.4812, 636.3618]])\n",
      "xyxyn: tensor([[0.2775, 0.0243, 0.7648, 0.9943]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.3498])\n",
      "data: tensor([[1.9718e+00, 9.7943e+00, 5.4563e+02, 6.3562e+02, 3.4984e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[273.7996, 322.7056, 543.6555, 625.8228]])\n",
      "xywhn: tensor([[0.4278, 0.5042, 0.8495, 0.9778]])\n",
      "xyxy: tensor([[  1.9718,   9.7943, 545.6273, 635.6170]])\n",
      "xyxyn: tensor([[0.0031, 0.0153, 0.8525, 0.9932]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.3118])\n",
      "data: tensor([[1.8577e+00, 9.0778e+00, 5.3679e+02, 6.3533e+02, 3.1180e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[269.3257, 322.2063, 534.9359, 626.2571]])\n",
      "xywhn: tensor([[0.4208, 0.5034, 0.8358, 0.9785]])\n",
      "xyxy: tensor([[  1.8577,   9.0778, 536.7936, 635.3348]])\n",
      "xyxyn: tensor([[0.0029, 0.0142, 0.8387, 0.9927]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.2694])\n",
      "data: tensor([[1.8142e+02, 1.7321e+01, 4.9018e+02, 6.4000e+02, 2.6936e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (640, 640)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[335.7987, 328.6604, 308.7634, 622.6792]])\n",
      "xywhn: tensor([[0.5247, 0.5135, 0.4824, 0.9729]])\n",
      "xyxy: tensor([[181.4170,  17.3208, 490.1804, 640.0000]])\n",
      "xyxyn: tensor([[0.2835, 0.0271, 0.7659, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74eb76-1663-4191-9877-fce88c077943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
